{
  "best_global_step": 240,
  "best_metric": 0.9547325102880658,
  "best_model_checkpoint": "./results\\checkpoint-240",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 1.3902450799942017,
      "learning_rate": 1.95e-05,
      "loss": 0.7038,
      "step": 10
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 2.405043840408325,
      "learning_rate": 1.8944444444444447e-05,
      "loss": 0.6835,
      "step": 20
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.400095224380493,
      "learning_rate": 1.838888888888889e-05,
      "loss": 0.657,
      "step": 30
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 3.3596248626708984,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 0.647,
      "step": 40
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.5808568000793457,
      "learning_rate": 1.727777777777778e-05,
      "loss": 0.6309,
      "step": 50
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4721120595932007,
      "learning_rate": 1.6722222222222225e-05,
      "loss": 0.6155,
      "step": 60
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 1.462343454360962,
      "learning_rate": 1.616666666666667e-05,
      "loss": 0.5709,
      "step": 70
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.6476081609725952,
      "learning_rate": 1.5611111111111113e-05,
      "loss": 0.5724,
      "step": 80
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8202040195465088,
      "learning_rate": 1.5055555555555556e-05,
      "loss": 0.5483,
      "step": 90
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1.6415070295333862,
      "learning_rate": 1.45e-05,
      "loss": 0.5173,
      "step": 100
    },
    {
      "epoch": 0.9166666666666666,
      "grad_norm": 1.5417945384979248,
      "learning_rate": 1.3944444444444446e-05,
      "loss": 0.4863,
      "step": 110
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.133310556411743,
      "learning_rate": 1.338888888888889e-05,
      "loss": 0.4645,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.95,
      "eval_f1_positive_class": 0.9504132231404959,
      "eval_f1_weighted": 0.9499965275366345,
      "eval_loss": 0.4455885887145996,
      "eval_precision_weighted": 0.95012503473187,
      "eval_recall_weighted": 0.95,
      "eval_runtime": 11.3933,
      "eval_samples_per_second": 21.065,
      "eval_steps_per_second": 2.633,
      "step": 120
    },
    {
      "epoch": 1.0833333333333333,
      "grad_norm": 1.426853895187378,
      "learning_rate": 1.2833333333333335e-05,
      "loss": 0.4376,
      "step": 130
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 1.670352578163147,
      "learning_rate": 1.227777777777778e-05,
      "loss": 0.4059,
      "step": 140
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.061128616333008,
      "learning_rate": 1.1722222222222224e-05,
      "loss": 0.3775,
      "step": 150
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.773258924484253,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 0.3822,
      "step": 160
    },
    {
      "epoch": 1.4166666666666667,
      "grad_norm": 1.3620525598526,
      "learning_rate": 1.0611111111111111e-05,
      "loss": 0.3318,
      "step": 170
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.4115275144577026,
      "learning_rate": 1.0055555555555557e-05,
      "loss": 0.3342,
      "step": 180
    },
    {
      "epoch": 1.5833333333333335,
      "grad_norm": 1.357757806777954,
      "learning_rate": 9.5e-06,
      "loss": 0.3153,
      "step": 190
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.2790982723236084,
      "learning_rate": 8.944444444444446e-06,
      "loss": 0.2541,
      "step": 200
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1200520992279053,
      "learning_rate": 8.38888888888889e-06,
      "loss": 0.2614,
      "step": 210
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 1.1158950328826904,
      "learning_rate": 7.833333333333333e-06,
      "loss": 0.2446,
      "step": 220
    },
    {
      "epoch": 1.9166666666666665,
      "grad_norm": 1.181908369064331,
      "learning_rate": 7.277777777777778e-06,
      "loss": 0.2249,
      "step": 230
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.419738531112671,
      "learning_rate": 6.7222222222222235e-06,
      "loss": 0.2659,
      "step": 240
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9541666666666667,
      "eval_f1_positive_class": 0.9547325102880658,
      "eval_f1_weighted": 0.9541595040891806,
      "eval_loss": 0.21958309412002563,
      "eval_precision_weighted": 0.9544506983531373,
      "eval_recall_weighted": 0.9541666666666667,
      "eval_runtime": 11.3955,
      "eval_samples_per_second": 21.061,
      "eval_steps_per_second": 2.633,
      "step": 240
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 1.4410502910614014,
      "learning_rate": 6.166666666666667e-06,
      "loss": 0.1855,
      "step": 250
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 0.9820366501808167,
      "learning_rate": 5.611111111111112e-06,
      "loss": 0.1692,
      "step": 260
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.3844294548034668,
      "learning_rate": 5.0555555555555555e-06,
      "loss": 0.2181,
      "step": 270
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.8776141405105591,
      "learning_rate": 4.5e-06,
      "loss": 0.1777,
      "step": 280
    },
    {
      "epoch": 2.4166666666666665,
      "grad_norm": 1.1793972253799438,
      "learning_rate": 3.944444444444445e-06,
      "loss": 0.1797,
      "step": 290
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.999563455581665,
      "learning_rate": 3.3888888888888893e-06,
      "loss": 0.2008,
      "step": 300
    },
    {
      "epoch": 2.5833333333333335,
      "grad_norm": 3.608895778656006,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 0.2111,
      "step": 310
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.6608444452285767,
      "learning_rate": 2.277777777777778e-06,
      "loss": 0.1684,
      "step": 320
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.0629912614822388,
      "learning_rate": 1.7222222222222224e-06,
      "loss": 0.1898,
      "step": 330
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 1.5989279747009277,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 0.1955,
      "step": 340
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 2.6774489879608154,
      "learning_rate": 6.111111111111112e-07,
      "loss": 0.2728,
      "step": 350
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.784257173538208,
      "learning_rate": 5.555555555555556e-08,
      "loss": 0.1573,
      "step": 360
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.95,
      "eval_f1_positive_class": 0.9508196721311475,
      "eval_f1_weighted": 0.9499861072520145,
      "eval_loss": 0.18023008108139038,
      "eval_precision_weighted": 0.9505005561735262,
      "eval_recall_weighted": 0.95,
      "eval_runtime": 8.1695,
      "eval_samples_per_second": 29.378,
      "eval_steps_per_second": 3.672,
      "step": 360
    }
  ],
  "logging_steps": 10,
  "max_steps": 360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 97338522009600.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
